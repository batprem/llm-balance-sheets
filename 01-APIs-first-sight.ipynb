{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f85f2661",
      "metadata": {
        "id": "f85f2661"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai \"httpx<0.28\"\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "TYPHOON_API_KEY = userdata.get('TYPHOON_API_KEY')\n",
        "MODEL = \"typhoon-v1.5x-70b-instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4ec3d376",
      "metadata": {
        "id": "4ec3d376",
        "outputId": "2761c557-1be0-4a7a-c741-8a8600afcbaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "สวัสดีค่ะ! ยินดีที่ได้พบคุณ. คุณต้องการความช่วยเหลือเกี่ยวกับอะไรคะ?\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "   api_key=TYPHOON_API_KEY,\n",
        "   base_url='https://api.opentyphoon.ai/v1'\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"typhoon-v1.5x-70b-instruct\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"สวัสดี\"}\n",
        "    ]\n",
        ")\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "755cf902",
      "metadata": {
        "id": "755cf902"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "class ChatTurn(TypedDict):\n",
        "    role: str\n",
        "    content: str\n",
        "\n",
        "def get_completion(\n",
        "    prompt: str,\n",
        "    model: str = MODEL,\n",
        "    stream: bool = False,\n",
        "    initial_message: list[ChatTurn]| None = None,\n",
        ") -> str:\n",
        "    if initial_message is None:\n",
        "        initial_message = []\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model, messages=messages, temperature=0, stream=stream\n",
        "    )\n",
        "    if not stream:\n",
        "        return response.choices[0].message.content\n",
        "    else:\n",
        "        result = \"\"\n",
        "        for chunk in response:\n",
        "            content = chunk.choices[0].delta.content\n",
        "            print(content, end=\"\")\n",
        "            if isinstance(content, str):\n",
        "                result += content\n",
        "        return result\n",
        "\n",
        "\n",
        "prompt = \"Explain the concept of prompt engineering.\"\n",
        "Markdown(get_completion(prompt, stream=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2a52c3b",
      "metadata": {
        "id": "f2a52c3b"
      },
      "source": [
        "# Chain of Thought prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ed0f14f",
      "metadata": {
        "id": "5ed0f14f"
      },
      "outputs": [],
      "source": [
        "def cot_prompt(question):\n",
        "    return f\"\"\"\n",
        "    Question: {question}\n",
        "    Let's approach this step-by-step:\n",
        "    1) First, let's understand what the question is asking.\n",
        "    2) Next, let's identify the key information provided.\n",
        "    3) Then, let's think about how to solve this problem.\n",
        "    4) Finally, let's calculate the answer.\n",
        "\n",
        "    Now, let's go through each step:\n",
        "    \"\"\"\n",
        "\n",
        "question = \"If a train travels 120 km in 2 hours, what is its average speed in km/h?\"\n",
        "cot_response = get_completion(cot_prompt(question))\n",
        "print(cot_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini"
      ],
      "metadata": {
        "id": "9wDtX21lXRjf"
      },
      "id": "9wDtX21lXRjf"
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.0-pro\")\n",
        "response = model.generate_content(get_completion(cot_prompt(question)))\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "wnqdcg3_XKmt"
      },
      "id": "wnqdcg3_XKmt",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}