{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85f2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "assert load_dotenv()\n",
    "from src.utils import get_completion\n",
    "from src.constants import TYPHOON_API_KEY\n",
    "\n",
    "\n",
    "\n",
    "MODEL = \"typhoon-v1.5x-70b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec3d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "สวัสดีค่ะ! ยินดีต้อนรับเข้าสู่การแชทกับฉัน ถ้ามีคำถามหรือต้องการความช่วยเหลือใด ๆ กรุณาแจ้งให้ทราบค่ะ\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "   api_key=TYPHOON_API_KEY,\n",
    "   base_url='https://api.opentyphoon.ai/v1'\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"typhoon-v1.5x-70b-instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"สวัสดี\"}\n",
    "    ]\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755cf902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering is the process of designing, optimizing, and fine-tuning natural language inputs, known as prompts, to elicit specific, desired responses from artificial intelligence (AI) systems, particularly language models. The goal is to maximize the quality, relevance, and usefulness of the AI's output by crafting well-defined, unambiguous, and contextually appropriate prompts.\n",
      "\n",
      "Prompt engineering involves understanding the capabilities and limitations of the AI model, as well as the task or problem at hand. It requires a deep understanding of linguistics, cognitive science, and the specific AI model's architecture and training data. Effective prompt engineering can significantly improve the performance of AI systems in various applications, such as chatbots, question-answering systems, text generation, and more.\n",
      "\n",
      "Some key aspects of prompt engineering include:\n",
      "\n",
      "1. Clarity and specificity: Crafting clear, concise, and specific prompts that minimize ambiguity and ensure the AI understands the task.\n",
      "2. Contextualization: Providing relevant context, background information, or examples to help the AI generate more accurate and relevant responses.\n",
      "3. Ambiguity reduction: Using techniques like disambiguation, paraphrasing, or providing multiple examples to reduce the chances of misinterpretation.\n",
      "4. Adversarial prompting: Designing prompts that test the AI's robustness and ability to handle edge cases, adversarial examples, or counterfactual scenarios.\n",
      "5. Iterative refinement: Continuously refining and updating prompts based on the AI's performance, feedback, and analysis of the generated responses.\n",
      "6. Model-aware prompting: Tailoring prompts to the specific characteristics, strengths, and weaknesses of the AI model, taking into account its training data, biases, and limitations.\n",
      "\n",
      "By applying these principles, prompt engineering can help unlock the full potential of AI systems, making them more reliable, efficient, and effective in assisting humans in various tasks and applications.None"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Prompt engineering is the process of designing, optimizing, and fine-tuning natural language inputs, known as prompts, to elicit specific, desired responses from artificial intelligence (AI) systems, particularly language models. The goal is to maximize the quality, relevance, and usefulness of the AI's output by crafting well-defined, unambiguous, and contextually appropriate prompts.\n",
       "\n",
       "Prompt engineering involves understanding the capabilities and limitations of the AI model, as well as the task or problem at hand. It requires a deep understanding of linguistics, cognitive science, and the specific AI model's architecture and training data. Effective prompt engineering can significantly improve the performance of AI systems in various applications, such as chatbots, question-answering systems, text generation, and more.\n",
       "\n",
       "Some key aspects of prompt engineering include:\n",
       "\n",
       "1. Clarity and specificity: Crafting clear, concise, and specific prompts that minimize ambiguity and ensure the AI understands the task.\n",
       "2. Contextualization: Providing relevant context, background information, or examples to help the AI generate more accurate and relevant responses.\n",
       "3. Ambiguity reduction: Using techniques like disambiguation, paraphrasing, or providing multiple examples to reduce the chances of misinterpretation.\n",
       "4. Adversarial prompting: Designing prompts that test the AI's robustness and ability to handle edge cases, adversarial examples, or counterfactual scenarios.\n",
       "5. Iterative refinement: Continuously refining and updating prompts based on the AI's performance, feedback, and analysis of the generated responses.\n",
       "6. Model-aware prompting: Tailoring prompts to the specific characteristics, strengths, and weaknesses of the AI model, taking into account its training data, biases, and limitations.\n",
       "\n",
       "By applying these principles, prompt engineering can help unlock the full potential of AI systems, making them more reliable, efficient, and effective in assisting humans in various tasks and applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "class ChatTurn(TypedDict):\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "def get_completion(\n",
    "    prompt: str,\n",
    "    model: str = MODEL,\n",
    "    stream: bool = False,\n",
    "    initial_message: list[ChatTurn]| None = None,\n",
    ") -> str:\n",
    "    if initial_message is None:\n",
    "        initial_message = []\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, messages=messages, temperature=0, stream=stream\n",
    "    )\n",
    "    if not stream:\n",
    "        return response.choices[0].message.content\n",
    "    else:\n",
    "        result = \"\"\n",
    "        for chunk in response:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            print(content, end=\"\")\n",
    "            if isinstance(content, str):\n",
    "                result += content\n",
    "        return result\n",
    "\n",
    "\n",
    "prompt = \"Explain the concept of prompt engineering.\"\n",
    "Markdown(get_completion(prompt, stream=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a52c3b",
   "metadata": {},
   "source": [
    "# Chain of Thought prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed0f14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Understand the question\n",
      "The question is asking for the average speed of a train that travels 120 km in 2 hours. Average speed is the total distance traveled divided by the total time taken.\n",
      "\n",
      "Step 2: Identify the key information\n",
      "The key information provided is:\n",
      "- Distance traveled = 120 km\n",
      "- Time taken = 2 hours\n",
      "\n",
      "Step 3: Think about how to solve this problem\n",
      "To find the average speed, we need to divide the total distance traveled by the total time taken. In this case, we can use the formula:\n",
      "\n",
      "Average Speed = Total Distance / Total Time\n",
      "\n",
      "Step 4: Calculate the answer\n",
      "Now, let's plug in the given values into the formula:\n",
      "\n",
      "Average Speed = 120 km / 2 hours\n",
      "Average Speed = 60 km/h\n",
      "\n",
      "So, the train's average speed is 60 km/h.\n"
     ]
    }
   ],
   "source": [
    "def cot_prompt(question):\n",
    "    return f\"\"\"\n",
    "    Question: {question}\n",
    "    Let's approach this step-by-step:\n",
    "    1) First, let's understand what the question is asking.\n",
    "    2) Next, let's identify the key information provided.\n",
    "    3) Then, let's think about how to solve this problem.\n",
    "    4) Finally, let's calculate the answer.\n",
    "    \n",
    "    Now, let's go through each step:\n",
    "    \"\"\"\n",
    "\n",
    "question = \"If a train travels 120 km in 2 hours, what is its average speed in km/h?\"\n",
    "cot_response = get_completion(cot_prompt(question))\n",
    "print(cot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80639e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
